# Laboratorio: Solución de Problemas de Rastreo (Crawler) con Clasificadores y Edición Manual

**Contexto:**
El equipo de taxis de Nueva York ha enviado un nuevo lote de datos, pero el formato ha cambiado. En lugar de comas (`,`), usan barras verticales o "pipes" (`|`). El Crawler estándar de Glue fallará al intentar leerlo.

**Objetivo:**
Aprender dos métodos para arreglar una definición de tabla incorrecta en el Data Catalog:
1.  **Edición Manual de SerDe:** Para arreglos rápidos y puntuales.
2.  **Custom Classifier:** Para arreglos automatizados y recurrentes.

---

## Paso 1: Generar el "Archivo Problemático"

1.  Crea un archivo llamado `taxi_pipes.csv` con el siguiente contenido:
    ```text
    VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|total_amount
    2|2025-01-01 00:00:00|2025-01-01 00:15:00|1|3.5|15.50
    1|2025-01-01 00:10:00|2025-01-01 00:25:00|2|1.2|10.00
    2|2025-01-01 00:20:00|2025-01-01 00:45:00|1|5.0|25.00
    ```
2.  Sube este archivo a una carpeta S3: `s3://tu-bucket/raw_pipes/taxi_pipes.csv`.

---

## Paso 2: El Fallo (Ejecutar Crawler Estándar)

1.  Crea un Crawler llamado `Crawler_Error_Pipe` apuntando a esa carpeta.
2.  Ejecútalo.
3.  Verifica en **Athena**: Verás que la tabla no tiene columnas separadas (o tiene nombres genéricos `col0`, `col1`) porque no entendió el delimitador `|`.

---

## Paso 3: Solución A - Editar la Tabla Manualmente (La solución rápida)

Si ya corriste el Crawler y creó la tabla mal, puedes arreglarla directamente en el Data Catalog sin volver a correr el Crawler.

1.  Ve a **AWS Glue** -> **Tables** y entra a la tabla `raw_pipes`.
2.  Haz clic en **Edit table** (arriba a la derecha). Or **Action** -> **Edit table**.
3.  Baja a la sección de **Schema** y haz clic en **Edit Schema** (o dependiendo de tu consola, busca las propiedades de la tabla).
4.  **Esta es la parte clave:** No basta con cambiar el nombre de las columnas, debes cambiar los parámetros de Serialización (**SerDe**).

### Referencia de Valores SerDe (Guárdalo para el futuro)
Si alguna vez necesitas cambiar el formato manualmente, usa estos valores:

> **Si es PARQUET:**
> * **Input format:** `org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat`
> * **Output format:** `org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat`
> * **SerDe lib:** `org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe`

> **Si es CSV:**
> * **Input format:** `org.apache.hadoop.mapred.TextInputFormat`
> * **Output format:** `org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat`
> * **SerDe lib:** `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe` (o `OpenCSVSerde`)

### Práctica: Arreglando nuestro archivo de Pipes
Como nuestro archivo es CSV pero con pipes (`|`):

1.  Asegúrate que **SerDe lib** sea: `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe`
2.  Busca la sección de **SerDe parameters**.
3.  Verás un parámetro llamado `field.delim` (o `separatorChar`). Probablemente tenga una coma `,`.
4.  Cámbialo por un pipe: `|`.
5.  Haz clic en **Save**.
6.  Ve a Athena y consulta la tabla de nuevo. ¡Debería verse bien ahora!

---

## Paso 4: Solución B - Crear un Custom Classifier (La solución robusta)

La solución manual (Paso 3) es buena para emergencias, pero si llega un archivo nuevo mañana, el Crawler lo volverá a hacer mal. Para automatizarlo, usamos un **Clasificador**.

1.  Ve a **Glue** -> **Classifiers** -> **Add classifier**.
2.  **Name:** `TaxiPipeClassifier`.
3.  **Type:** `CSV`.
4.  **Delimiter:** `Other` -> `|`.
5.  **Headings:** `Detect headings`.
6.  Guarda el clasificador.

**Re-configurar el Crawler:**
1.  Edita tu `Crawler_Error_Pipe`.
2.  En **Output configuration** (o Advanced), agrega el `TaxiPipeClassifier` a la lista de seleccionados.
3.  Vuelve a ejecutar el Crawler.
    * *Nota:* Ahora, cada vez que este Crawler corra, sabrá automáticamente cómo leer estos archivos sin ayuda manual.

---

## Conclusión

* Usa la **Edición Manual (SerDe)** cuando necesites arreglar una tabla urgentemente y no quieras re-escanear los datos.
* Usa **Custom Classifiers** cuando quieras construir un pipeline robusto que no requiera intervención humana constante.